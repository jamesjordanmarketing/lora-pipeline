# LoRA Training Infrastructure - Complete Testing Tutorial

## Overview
This tutorial will guide you through testing **every feature** of the BrightRun LoRA Training Infrastructure application. You'll follow a complete training workflow from start to finish, testing all functionality across the five wireframes (P01-P05).

**Estimated Time:** 30-45 minutes  
**Technical Level:** No technical knowledge required  
**What You'll Do:** Create a trained LoRA model from a conversation dataset

---

## Tutorial Structure

This tutorial follows the natural workflow of training a LoRA model:

1. **P01 - Dashboard Shell** (Start here)
2. **P02 - Dataset Management** (Select your data)
3. **P03 - Training Configurator** (Configure training)
4. **P04 - Training Monitor** (Watch it train)
5. **P05 - Model Artifacts** (Get your trained model)

---

## Before You Start

### Prerequisites
- Application is running and accessible in your browser
- You have the application open in a browser window

### What to Expect
- All data you see is **mock data** (simulated for testing)
- No real training happens - everything is simulated
- You can safely click any button without breaking anything
- Some features show "Coming Soon" alerts - this is expected

---

# PART 1: Dashboard Shell & Global Navigation (P01)

## Section 1.1: Initial Dashboard View

### Test 1: View the Main Dashboard
**What to test:** The overall layout and shell

**Steps:**
1. Open the application homepage
2. Observe the main layout

**What you should see:**
- ‚úÖ Left sidebar with navigation menu
- ‚úÖ Top header bar
- ‚úÖ Main content area showing dashboard
- ‚úÖ "BrightRun LoRA Training" logo in the top-left

**Success:** You can see all four main areas of the interface

---

## Section 1.2: Sidebar Navigation

### Test 2: Navigate Through All Menu Items
**What to test:** All navigation links work

**Steps:**
1. Look at the left sidebar
2. Click each navigation item one by one:
   - üìä **Dashboard** (Overview icon)
   - üìÅ **Datasets** (Database icon)
   - ‚öôÔ∏è **Training Jobs** (Settings icon)
   - ü§ñ **Models** (Package icon)

**What you should see:**
- ‚úÖ Each click changes the main content area
- ‚úÖ The clicked item highlights in blue
- ‚úÖ Previous item unhighlights
- ‚úÖ Content area updates to show relevant information

**Success:** All four navigation items are clickable and show different content

---

### Test 3: View Active Training Indicator
**What to test:** Header shows active training jobs

**Steps:**
1. Look at the top header bar (right side)
2. Find the "Active Training" indicator

**What you should see:**
- ‚úÖ Orange/amber badge showing "2 Active"
- ‚úÖ Clicking it shows a dropdown with active jobs
- ‚úÖ Each job shows:
  - Job name
  - Progress percentage
  - Current stage
  - "View" button

**Success:** You can see active training jobs and click "View" on any job

---

## Section 1.3: Header Features

### Test 4: View Cost Tracker
**What to test:** Current spending display

**Steps:**
1. Look at the top header bar
2. Find the cost display (dollar sign icon)

**What you should see:**
- ‚úÖ Current spending amount (e.g., "$127.45")
- ‚úÖ Green/yellow/red color based on spending level
- ‚úÖ Clicking opens a dropdown showing:
  - This month's spending
  - Cost breakdown
  - Budget alerts (if any)

**Success:** Cost tracker displays and dropdown opens

---

### Test 5: View Notifications
**What to test:** Notification bell and alerts

**Steps:**
1. Look at the top header bar (right side)
2. Click the bell icon (üîî)

**What you should see:**
- ‚úÖ Red badge showing number of unread notifications
- ‚úÖ Dropdown panel opens showing:
  - Training completions
  - Cost warnings
  - System alerts
- ‚úÖ Each notification has a timestamp
- ‚úÖ "Mark all as read" button at bottom

**Success:** Notification panel opens and shows alerts

---

### Test 6: User Profile Menu
**What to test:** User account access

**Steps:**
1. Look at the top-right corner
2. Click the user avatar/initials (e.g., "JD")

**What you should see:**
- ‚úÖ Dropdown menu opens showing:
  - User name and email
  - "Profile" option
  - "Settings" option
  - "Sign Out" option
- ‚úÖ Each option is clickable (may show "Coming Soon" for some)

**Success:** User menu opens with all options

---

## Section 1.4: Breadcrumb Navigation

### Test 7: View and Use Breadcrumbs
**What to test:** Breadcrumb trail for navigation

**Steps:**
1. Navigate to any sub-page (e.g., click "Datasets")
2. Look at the top of the main content area
3. Observe the breadcrumb trail (e.g., "Home > Datasets")

**What you should see:**
- ‚úÖ Breadcrumb path showing current location
- ‚úÖ Each breadcrumb item is clickable
- ‚úÖ Clicking "Home" returns to dashboard

**Success:** Breadcrumbs show your location and allow navigation

---

# PART 2: Dataset Management View (P02)

## Section 2.1: Viewing Datasets

### Test 8: Access Dataset Management
**What to test:** Navigate to datasets view

**Steps:**
1. Click "Datasets" in the left sidebar
2. Wait for the page to load

**What you should see:**
- ‚úÖ Page title: "Dataset Management"
- ‚úÖ Grid of dataset cards (3-4 cards visible)
- ‚úÖ "Upload Dataset" button in top-right
- ‚úÖ Breadcrumb: "Home > Datasets"

**Success:** Dataset management page loads with multiple dataset cards

---

### Test 9: Examine Dataset Cards
**What to test:** Dataset card information display

**Steps:**
1. Look at the first dataset card (should be "Healthcare Consultant Conversations")
2. Examine all information displayed

**What you should see on each card:**
- ‚úÖ Dataset name as title
- ‚úÖ Consultant name and title (e.g., "Elena Morales, CFP")
- ‚úÖ Creation date
- ‚úÖ Number of training pairs (e.g., "1,567 pairs")
- ‚úÖ Quality score (e.g., "92% Ready")
- ‚úÖ Progress bars for:
  - Persona Coverage (87%)
  - Arc Coverage (92%)
- ‚úÖ Status badge (e.g., "Ready", "Processing")
- ‚úÖ "View Details" button
- ‚úÖ "Start Training" button

**Success:** All dataset information is clearly visible

---

### Test 10: Filter and Search Datasets
**What to test:** Dataset filtering functionality

**Steps:**
1. Look for filter/search controls at the top
2. Try filtering by:
   - Status (Ready, Processing, Draft)
   - Vertical (Healthcare, Finance, Legal)
3. Try the search box (if present)

**What you should see:**
- ‚úÖ Filter dropdown menus work
- ‚úÖ Dataset cards update based on filters
- ‚úÖ Card count changes with filters
- ‚úÖ "Clear filters" option available

**Success:** Filtering changes which datasets are displayed

---

### Test 11: View Dataset Details (Modal)
**What to test:** Detailed dataset information

**Steps:**
1. Click "View Details" on the "Healthcare Consultant Conversations" dataset
2. Wait for modal/detail view to open

**What you should see:**
- ‚úÖ Modal dialog opens overlaying the page
- ‚úÖ Full dataset information:
  - Complete name
  - Consultant profile with photo/avatar
  - Total conversation pairs
  - Quality metrics
  - Scaffolding analysis details
- ‚úÖ Sample conversation pairs (at least 2-3 examples)
- ‚úÖ Each sample shows:
  - User message
  - Assistant response
  - Persona/Arc tags
- ‚úÖ Quality indicators for each sample
- ‚úÖ "Close" button (X or Cancel)
- ‚úÖ "Start Training" button in modal

**Success:** Modal opens with complete dataset details and samples

---

### Test 12: View Scaffolding Analysis
**What to test:** Persona and Arc coverage analysis

**Steps:**
1. Inside the dataset details modal, find the "Scaffolding Analysis" section
2. Examine the coverage information

**What you should see:**
- ‚úÖ Persona Coverage percentage (e.g., 87%)
- ‚úÖ Arc Coverage percentage (e.g., 92%)
- ‚úÖ Visual progress bars
- ‚úÖ List or breakdown of covered personas:
  - Empathetic Advisor
  - Analytical Consultant
  - Supportive Guide
- ‚úÖ List or breakdown of covered arcs:
  - Discovery
  - Problem-Solving
  - Decision-Making
  - Follow-up

**Success:** Scaffolding coverage shows what conversation patterns are included

---

### Test 13: Close Dataset Details Modal
**What to test:** Modal close functionality

**Steps:**
1. While viewing dataset details, click the "X" or "Close" button
2. Alternatively, click outside the modal (on the darkened background)

**What you should see:**
- ‚úÖ Modal closes smoothly
- ‚úÖ You return to the dataset grid view
- ‚úÖ No data is lost

**Success:** Modal closes and returns to main view

---

## Section 2.2: Starting Training from Dataset

### Test 14: Initiate Training Job
**What to test:** Starting training from a dataset

**Steps:**
1. From the dataset grid, find "Healthcare Consultant Conversations"
2. Click the "Start Training" button on that card

**What you should see:**
- ‚úÖ Page transitions to Training Configurator (P03)
- ‚úÖ Dataset name is pre-filled
- ‚úÖ Breadcrumb updates to: "Home > Datasets > Training Configuration"
- ‚úÖ You're ready to configure training

**Success:** Clicking "Start Training" takes you to P03 configuration

---

# PART 3: Training Job Configurator (P03)

## Section 3.1: Initial Configuration View

### Test 15: View Training Configuration Page
**What to test:** Configuration page layout

**Steps:**
1. You should now be on the Training Configuration page (from previous test)
2. Examine the page layout

**What you should see:**
- ‚úÖ Page title: "Configure Training Job"
- ‚úÖ Selected dataset displayed prominently:
  - Dataset name
  - Number of pairs
  - Quality score
- ‚úÖ Three main sections visible:
  - Preset Selection
  - Advanced Settings (collapsed)
  - Cost Estimation (right sidebar)
- ‚úÖ "Start Training" button (primary, bottom-right)
- ‚úÖ "Cancel" or "Back" button

**Success:** Configuration page loads with all sections visible

---

## Section 3.2: Preset Selection

### Test 16: View Training Presets
**What to test:** Three preset options

**Steps:**
1. Look at the "Select Training Preset" section
2. Examine all three preset cards

**What you should see (3 cards):**

**Conservative Preset:**
- ‚úÖ Title: "Conservative"
- ‚úÖ Description: "Safer, slower training"
- ‚úÖ Estimated cost: "$25-35"
- ‚úÖ Estimated time: "6-8 hours"
- ‚úÖ Risk level: "Low"
- ‚úÖ Radio button or select option

**Balanced Preset (Recommended):**
- ‚úÖ Title: "Balanced"
- ‚úÖ Badge: "Recommended"
- ‚úÖ Description: "Good balance of speed and quality"
- ‚úÖ Estimated cost: "$45-55"
- ‚úÖ Estimated time: "8-12 hours"
- ‚úÖ Risk level: "Medium"
- ‚úÖ Radio button or select option (default selected)

**Aggressive Preset:**
- ‚úÖ Title: "Aggressive"
- ‚úÖ Description: "Fastest training, higher resource usage"
- ‚úÖ Estimated cost: "$80-100"
- ‚úÖ Estimated time: "4-6 hours"
- ‚úÖ Risk level: "High"
- ‚úÖ Radio button or select option

**Success:** All three presets are clearly visible with costs and times

---

### Test 17: Switch Between Presets
**What to test:** Preset selection updates estimates

**Steps:**
1. Click on "Conservative" preset
2. Watch the Cost Estimation sidebar (right side)
3. Click on "Aggressive" preset
4. Watch the Cost Estimation update again
5. Return to "Balanced" preset

**What you should see:**
- ‚úÖ Clicking a preset highlights that card
- ‚úÖ Cost Estimation sidebar updates immediately:
  - Estimated cost range changes
  - Estimated duration changes
  - GPU configuration may change
- ‚úÖ Only one preset can be selected at a time

**Success:** Switching presets updates cost estimates in real-time

---

## Section 3.3: Advanced Settings

### Test 18: Expand Advanced Settings
**What to test:** Advanced configuration panel

**Steps:**
1. Find the "Advanced Settings" section (should be collapsed by default)
2. Click to expand it

**What you should see:**
- ‚úÖ Panel expands smoothly
- ‚úÖ Multiple hyperparameter controls appear:
  - **LoRA Rank (r):** Slider (8-64)
  - **LoRA Alpha (Œ±):** Slider (16-128)
  - **Learning Rate:** Dropdown or input (1e-5 to 5e-4)
  - **Number of Epochs:** Slider (1-5)
  - **Batch Size:** Dropdown (2, 4, 8)
  - **Dropout:** Slider (0.0-0.2)
- ‚úÖ Each control shows current value
- ‚úÖ Help text or tooltips explain each parameter

**Success:** Advanced settings panel opens and shows all hyperparameters

---

### Test 19: Adjust Hyperparameters
**What to test:** Changing individual settings

**Steps:**
1. With Advanced Settings open, adjust the LoRA Rank slider
2. Change the Learning Rate
3. Adjust Number of Epochs

**What you should see:**
- ‚úÖ Slider values update as you drag
- ‚úÖ Current value displays next to slider
- ‚úÖ Cost Estimation updates when you change values
- ‚úÖ Warning appears if you use extreme values
- ‚úÖ Visual feedback shows you're editing

**Success:** Hyperparameters are adjustable and update cost estimates

---

### Test 20: View Hyperparameter Tooltips
**What to test:** Help information for parameters

**Steps:**
1. Hover over or click the "?" or "info" icon next to "LoRA Rank"
2. Try the same for other parameters

**What you should see:**
- ‚úÖ Tooltip or info popup appears
- ‚úÖ Explanation of what the parameter does
- ‚úÖ Recommended values
- ‚úÖ Impact on training (e.g., "Higher = more capacity")

**Success:** Help tooltips explain each hyperparameter

---

### Test 21: Collapse Advanced Settings
**What to test:** Collapsing the panel

**Steps:**
1. Click the Advanced Settings header again to collapse
2. Observe the result

**What you should see:**
- ‚úÖ Panel collapses smoothly
- ‚úÖ Your changes are saved
- ‚úÖ Cost estimates remain updated
- ‚úÖ You can re-expand to see your settings

**Success:** Advanced settings collapse without losing changes

---

## Section 3.4: Cost Estimation

### Test 22: View Cost Estimation Breakdown
**What to test:** Detailed cost calculation

**Steps:**
1. Look at the Cost Estimation card/sidebar (right side)
2. Examine all displayed information

**What you should see:**
- ‚úÖ **Estimated Cost Range:** "$45-55" (large, prominent)
- ‚úÖ **Estimated Duration:** "8-12 hours"
- ‚úÖ **GPU Configuration:**
  - GPU type (e.g., "H100 PCIe 80GB")
  - Instance type badge ("Spot" or "On-Demand")
  - Hourly rate (e.g., "$2.49/hr")
- ‚úÖ **Cost Breakdown:**
  - Compute cost
  - Storage cost
  - Total estimated
- ‚úÖ **Savings indicator:** If using Spot instances
- ‚úÖ Color coding (green for good, yellow for expensive)

**Success:** Complete cost breakdown is visible and understandable

---

### Test 23: Change GPU Instance Type
**What to test:** Spot vs On-Demand pricing

**Steps:**
1. Look for instance type selector in Cost Estimation
2. Toggle between "Spot" and "On-Demand"

**What you should see:**
- ‚úÖ Toggle or dropdown switches between types
- ‚úÖ Cost estimate updates:
  - Spot: Lower cost (e.g., "$45-55")
  - On-Demand: Higher cost (e.g., "$120-140")
- ‚úÖ Hourly rate changes
- ‚úÖ Warning about Spot interruption risk
- ‚úÖ Recommendation badge

**Success:** Switching instance types updates costs dramatically

---

## Section 3.5: Validation Checklist

### Test 24: View Pre-Flight Validation
**What to test:** Training readiness checks

**Steps:**
1. Scroll down to find the "Validation Checklist" section
2. Examine all checklist items

**What you should see (checklist items):**
- ‚úÖ "Dataset selected and validated" (green checkmark)
- ‚úÖ "Sufficient training pairs (>100)" (green checkmark)
- ‚úÖ "GPU resources available" (green checkmark or yellow warning)
- ‚úÖ "Configuration valid" (green checkmark)
- ‚úÖ "Cost within budget" (green or yellow based on amount)
- ‚úÖ "Required fields complete" (green checkmark)

**Each item shows:**
- ‚úÖ Green checkmark = passed
- ‚úÖ Yellow warning = attention needed
- ‚úÖ Red X = blocking issue

**Success:** Validation checklist shows all requirements

---

### Test 25: Trigger Validation Warning
**What to test:** Validation failure state

**Steps:**
1. Expand Advanced Settings
2. Set LoRA Rank to maximum (64)
3. Set Epochs to maximum (5)
4. Set Batch Size to maximum (8)
5. Check validation checklist

**What you should see:**
- ‚úÖ "Cost within budget" may turn yellow/red
- ‚úÖ Warning message appears
- ‚úÖ Estimated cost is very high (e.g., "$150-200")
- ‚úÖ "Start Training" button may show warning color

**Success:** System warns about expensive configurations

---

## Section 3.6: Launching Training

### Test 26: Review Launch Summary
**What to test:** Pre-launch confirmation

**Steps:**
1. Reset to "Balanced" preset (if you changed settings)
2. Click the "Start Training" button
3. Wait for confirmation modal

**What you should see:**
- ‚úÖ Confirmation modal/dialog opens
- ‚úÖ Modal title: "Confirm Training Job"
- ‚úÖ Summary of configuration:
  - Dataset name
  - Preset used
  - Estimated cost
  - Estimated duration
- ‚úÖ Final validation checks
- ‚úÖ Two buttons:
  - "Cancel" or "Go Back"
  - "Confirm & Start Training" (primary/green)

**Success:** Confirmation modal shows complete training summary

---

### Test 27: Launch Training Job
**What to test:** Starting the training process

**Steps:**
1. In the confirmation modal, click "Confirm & Start Training"
2. Watch for the response

**What you should see:**
- ‚úÖ Modal closes
- ‚úÖ Success message/toast appears: "Training job started!"
- ‚úÖ Confetti animation (celebration) üéâ
- ‚úÖ Page automatically navigates to Training Monitor (P04)
- ‚úÖ Breadcrumb updates to: "Home > Training Jobs > [Job Name]"
- ‚úÖ Training job is now running

**Success:** Training launches and you're taken to the monitoring page

---

# PART 4: Training Progress Monitor (P04)

## Section 4.1: Initial Monitor View

### Test 28: View Training Monitor Dashboard
**What to test:** Monitor page layout and initial state

**Steps:**
1. You should now be on the Training Monitor page (from previous test)
2. Examine the page layout

**What you should see:**
- ‚úÖ Page title: "Training Monitor"
- ‚úÖ Job ID displayed (e.g., "job-1734643200-abc123")
- ‚úÖ Five main sections:
  1. Progress Header Card
  2. Stage Progression Indicator
  3. Loss Curve Graph
  4. Current Metrics Table
  5. Cost Tracker Card
- ‚úÖ "Refresh" button (top-right)
- ‚úÖ "Cancel Job" button (red, prominent)

**Success:** Training monitor loads showing all sections

---

## Section 4.2: Progress Header

### Test 29: View Overall Progress
**What to test:** Progress header information

**Steps:**
1. Look at the top Progress Header Card
2. Examine all displayed information

**What you should see:**
- ‚úÖ **Job Name:** "Healthcare Consultant - Balanced"
- ‚úÖ **Dataset Info:** "Training on: Healthcare Consultant Conversations (1,567 pairs)"
- ‚úÖ **Status Badge:** "Training" (blue, pulsing animation)
- ‚úÖ **Progress Bar:** Animated, showing percentage (e.g., 42%)
- ‚úÖ **Progress Percentage:** Large number (e.g., "42%")
- ‚úÖ **Current Step:** "850 / 2,000"
- ‚úÖ **Current Epoch:** "2 / 3"
- ‚úÖ **Elapsed Time:** "6h 23m"
- ‚úÖ **Estimated Remaining:** "8h 15m remaining" (blue text)
- ‚úÖ **Current Losses:** Training and Validation loss preview

**Success:** Progress header shows complete training status at a glance

---

### Test 30: Monitor Progress Changes
**What to test:** Progress updates over time

**Steps:**
1. Wait 10 seconds (the app auto-completes training in demo)
2. Watch the progress header

**What you should see (if auto-completion triggers):**
- ‚úÖ Progress percentage increases
- ‚úÖ Progress bar fills
- ‚úÖ Status badge changes to "Completed" (green)
- ‚úÖ Confetti animation appears üéâ
- ‚úÖ Success banner appears at top

**Success:** Progress updates automatically (in real system, this happens every 60 seconds)

---

## Section 4.3: Stage Progression

### Test 31: View Training Stages
**What to test:** Four-stage progression indicator

**Steps:**
1. Find the "Training Stages" section
2. Examine the horizontal stage indicator

**What you should see (4 stages):**

**Stage 1 - Preprocessing:**
- ‚úÖ Green circle with checkmark ‚úì
- ‚úÖ "Completed" label
- ‚úÖ Duration shown: "3m 42s"

**Stage 2 - Model Loading:**
- ‚úÖ Green circle with checkmark ‚úì
- ‚úÖ "Completed" label
- ‚úÖ Duration shown: "11m 18s"

**Stage 3 - Training:**
- ‚úÖ Blue circle with spinning loader
- ‚úÖ "In Progress" label (pulsing)
- ‚úÖ Substatus message: "Epoch 2/3 - Step 850/2000 - Loss converging"

**Stage 4 - Finalization:**
- ‚úÖ Gray circle with number
- ‚úÖ "Pending" label
- ‚úÖ Estimated time: "5-10m"

**Additional:**
- ‚úÖ Connecting lines between stages
- ‚úÖ Green line shows completed progress
- ‚úÖ Gray line shows remaining progress

**Success:** All four stages visible with clear status indicators

---

### Test 32: View Active Stage Details
**What to test:** Substatus information

**Steps:**
1. Look below the stage progression indicator
2. Find the active stage substatus box

**What you should see:**
- ‚úÖ Blue highlighted box
- ‚úÖ Current stage name: "Training"
- ‚úÖ Detailed substatus: "Epoch 2/3 - Step 850/2000 - Loss converging"
- ‚úÖ Updates with stage progress

**Success:** Active stage shows detailed status information

---

## Section 4.4: Loss Curve Graph

### Test 33: View Loss Curve Chart
**What to test:** Training and validation loss visualization

**Steps:**
1. Find the "Loss Curve" card
2. Examine the graph

**What you should see:**
- ‚úÖ **Chart Title:** "Loss Curve"
- ‚úÖ **Subtitle:** "Training and validation loss over time"
- ‚úÖ **Two Lines:**
  - Blue solid line = Training Loss
  - Orange dashed line = Validation Loss
- ‚úÖ **X-axis:** Training steps (0 to current step)
- ‚úÖ **Y-axis:** Loss values (decreasing trend)
- ‚úÖ **Legend:** Shows both line types
- ‚úÖ **Export Button:** "Export PNG" (top-right)

**Success:** Graph displays with both loss curves clearly visible

---

### Test 34: Interact with Loss Curve
**What to test:** Interactive chart features

**Steps:**
1. Hover your mouse over the loss curve lines
2. Move along different points

**What you should see:**
- ‚úÖ Tooltip appears on hover
- ‚úÖ Tooltip shows:
  - Step number
  - Training loss value (4 decimal places)
  - Validation loss value (4 decimal places)
- ‚úÖ Vertical line follows your cursor
- ‚úÖ Exact values displayed

**Success:** Hovering shows exact loss values at each step

---

### Test 35: Export Loss Curve
**What to test:** Chart export functionality

**Steps:**
1. Click the "Export PNG" button on the loss curve card

**What you should see:**
- ‚úÖ Alert or message: "Chart export feature would download a 2000x1200px PNG here"
- ‚úÖ (In real app, a PNG file would download)

**Success:** Export button is functional (shows placeholder in demo)

---

## Section 4.5: Current Metrics Table

### Test 36: View Training Metrics
**What to test:** Detailed metrics display

**Steps:**
1. Find the "Current Metrics" table
2. Examine all rows

**What you should see (7 metric rows):**

| Metric | Value | Trend |
|--------|-------|-------|
| **Training Loss** | 0.3420 | ‚Üì -12.1% (green) |
| **Validation Loss** | 0.3580 | ‚Üì -13.1% (green) |
| **Learning Rate** | 0.000182 | (trend arrow) |
| **GPU Utilization** | 87% | (trend arrow) |
| **GPU Memory** | 68GB / 80GB (85%) | - |
| **Perplexity** | 1.43 | ‚Üì (green) |
| **Tokens/Second** | 1,247 | (trend arrow) |

**For each metric:**
- ‚úÖ Metric name (left column)
- ‚úÖ Current value (middle, bold)
- ‚úÖ Trend indicator (right):
  - Green ‚Üì arrow = improvement
  - Red ‚Üë arrow = worsening
  - Gray - = stable
- ‚úÖ Percentage change shown

**Success:** All metrics visible with trends clearly indicated

---

### Test 37: Understand Metric Trends
**What to test:** Trend indicators meaning

**Steps:**
1. Look at Training Loss trend (should be green down arrow)
2. Look at Perplexity trend (should be green down arrow)
3. Note the percentage changes

**What you should understand:**
- ‚úÖ **Green ‚Üì** = Good (loss decreasing)
- ‚úÖ **Red ‚Üë** = Bad (loss increasing)
- ‚úÖ **Percentage** = Change from last update
- ‚úÖ **For loss/perplexity:** Lower is better
- ‚úÖ **For GPU utilization:** Higher is better

**Success:** You understand what trends mean

---

### Test 38: View Metrics Update Notice
**What to test:** Update frequency information

**Steps:**
1. Scroll to bottom of metrics table
2. Find the info message

**What you should see:**
- ‚úÖ Gray info box
- ‚úÖ Message: "Metrics update every 60 seconds during training. Trends show change from previous update."

**Success:** Update frequency is clearly communicated

---

## Section 4.6: Cost Tracker

### Test 39: View Real-Time Cost Tracking
**What to test:** Cost accumulation display

**Steps:**
1. Find the "Cost Tracker" card (usually right sidebar)
2. Examine all cost information

**What you should see:**
- ‚úÖ **Card Title:** "Cost Tracker"
- ‚úÖ **Subtitle:** "Real-time spending"
- ‚úÖ **Instance Type Badge:** "Spot" (green) or "On-Demand"
- ‚úÖ **Current Spend:** "$22.18" (large, bold, blue)
- ‚úÖ **Progress Bar:** Showing percentage of estimate
- ‚úÖ **Percentage:** "49% of estimate"
- ‚úÖ **Estimated Range:** "$45-55" (gray)
- ‚úÖ **Hourly Rate:** "$2.49/hr"
- ‚úÖ **Projected Final:** "$47.32"

**Success:** All cost information is clearly displayed

---

### Test 40: Interpret Cost Progress Bar
**What to test:** Cost status visualization

**Steps:**
1. Look at the cost progress bar color
2. Note the percentage

**What you should see:**
- ‚úÖ **Green bar** = Under 80% of estimate (good)
- ‚úÖ **Yellow bar** = 80-100% of estimate (warning)
- ‚úÖ **Red bar** = Over 100% of estimate (exceeded)
- ‚úÖ Current example: Green at 49%

**Success:** Color coding shows cost status at a glance

---

### Test 41: View Cost Warning (If Testing Cost Warning State)
**What to test:** Cost exceeded alert

**Note:** To test this, you need to view the cost warning demo state. This might require a special parameter or switching datasets.

**What you should see (if cost exceeds estimate):**
- ‚úÖ **Red border** on cost tracker card
- ‚úÖ **Pulsing animation** on card
- ‚úÖ **Alert banner:**
  - Red background
  - ‚ö†Ô∏è Warning icon
  - "Cost Exceeding Estimate!" message
  - Explanation text
- ‚úÖ Current spend shown in red (e.g., "$54.23")
- ‚úÖ Percentage over 100% (e.g., "121%")

**Success:** Cost warnings are highly visible and clear

---

## Section 4.7: Control Actions

### Test 42: Manual Refresh
**What to test:** Manual metrics update

**Steps:**
1. Find the "Refresh" button (top-right)
2. Click it

**What you should see:**
- ‚úÖ Button briefly shows loading state
- ‚úÖ Toast notification: "Metrics updated"
- ‚úÖ All metrics refresh
- ‚úÖ Loss curve adds new points
- ‚úÖ "Last update" timestamp updates

**Success:** Manual refresh updates all metrics

---

### Test 43: Open Cancel Job Modal
**What to test:** Training cancellation interface

**Steps:**
1. Find the "Cancel Job" button (red, top-right)
2. Click it

**What you should see:**
- ‚úÖ Modal dialog opens
- ‚úÖ Title: "Cancel Training Job" with ‚ö†Ô∏è icon
- ‚úÖ Warning message about cancellation
- ‚úÖ **Current Progress Summary:**
  - Progress: "42% Complete"
  - Cost Incurred: "$22.18"
  - Current Loss: "0.3420"
  - Current Epoch: "2 / 3"
- ‚úÖ **Impact Warning:**
  - Training stops immediately
  - Progress lost
  - Still charged for GPU time
  - Dataset unaffected
- ‚úÖ **Reason Selection:** (required)
  - ‚óã Cost exceeding budget
  - ‚óã Poor training performance
  - ‚óã Incorrect configuration
  - ‚óã No longer needed
  - ‚óã Other reason

**Success:** Cancellation modal shows complete impact summary

---

### Test 44: Select Cancellation Reason
**What to test:** Reason requirement

**Steps:**
1. In the cancel modal, try clicking "Confirm Cancellation" without selecting a reason
2. Then select a reason (e.g., "Cost exceeding budget")
3. Try clicking "Confirm Cancellation" again

**What you should see:**
- ‚úÖ Button is disabled when no reason selected
- ‚úÖ Selecting a reason enables the button
- ‚úÖ Selected reason highlights
- ‚úÖ Can only select one reason

**Success:** Cancellation requires selecting a reason

---

### Test 45: Confirm Cancellation
**What to test:** Actually cancelling the job

**Steps:**
1. With a reason selected, click "Confirm Cancellation"
2. Watch the process

**What you should see:**
- ‚úÖ Button shows loading state: "Cancelling..."
- ‚úÖ Brief delay (simulating API call)
- ‚úÖ Modal closes
- ‚úÖ Status badge changes to "Cancelled"
- ‚úÖ Toast notification: "Training Job Cancelled"
- ‚úÖ Reason shown in notification
- ‚úÖ All progress stops
- ‚úÖ "Cancel Job" button disappears

**Success:** Job is cancelled and status updates

**Note:** For continued testing, you may need to refresh the page or start a new training job.

---

### Test 46: Cancel Modal Without Confirming
**What to test:** Closing modal without action

**Steps:**
1. Open the cancel modal again
2. Click "Keep Training" or the X button
3. Or click outside the modal

**What you should see:**
- ‚úÖ Modal closes
- ‚úÖ No changes to training job
- ‚úÖ Training continues normally
- ‚úÖ No notification appears

**Success:** Can close modal without cancelling

---

## Section 4.8: Completion State

### Test 47: View Training Completion
**What to test:** Successful completion display

**Note:** The demo app auto-completes after 10 seconds. Wait for this or refresh to see completion state.

**Steps:**
1. Wait for training to complete (or use completion demo state)
2. Observe all changes

**What you should see:**
- ‚úÖ **Progress:** 100%
- ‚úÖ **Status Badge:** "Completed" (green)
- ‚úÖ **Confetti Animation:** üéâ
- ‚úÖ **Completion Banner:**
  - Green background
  - üéâ "Training Complete!" message
  - "Final loss: 0.312" displayed
  - Large success indicator
- ‚úÖ **All Stages Green:**
  - Preprocessing ‚úì
  - Model Loading ‚úì
  - Training ‚úì
  - Finalization ‚úì
- ‚úÖ **Final Metrics Displayed:**
  - Final Training Loss: 0.312
  - Final Validation Loss: 0.328
  - Final Perplexity: 1.39
- ‚úÖ **Action Buttons:**
  - "View LoRA Model" (primary, green)
  - "Download Artifacts" (secondary)

**Success:** Completion is celebrated and clearly indicated

---

### Test 48: Navigate to Model Artifacts
**What to test:** Transition to P05

**Steps:**
1. With training completed, click "View LoRA Model" button

**What you should see:**
- ‚úÖ Toast notification: "Navigating to model artifacts..."
- ‚úÖ Page transitions to Model Artifacts page (P05)
- ‚úÖ Breadcrumb updates to: "Home > Models > [Model Name]"
- ‚úÖ Model information loads

**Success:** "View LoRA Model" button takes you to P05

---

# PART 5: Model Artifacts Manager (P05)

## Section 5.1: Model Overview

### Test 49: View Model Artifacts Page
**What to test:** Model artifacts page layout

**Steps:**
1. You should now be on the Model Artifacts page (from previous test)
2. Examine the page layout

**What you should see:**
- ‚úÖ Page title: "Model Artifacts"
- ‚úÖ Subtitle: "Trained LoRA adapter ready for deployment"
- ‚úÖ "Show Version History" button (top-right)
- ‚úÖ **Model Card Header:**
  - Model name (e.g., "Healthcare-Balanced-20241213")
  - Status badge (e.g., "Stored")
  - Creation date
  - Base model (e.g., "Llama 3 70B Instruct")
  - Quick stats (Job ID, pairs, duration, cost)
- ‚úÖ Main content divided into two columns:
  - Left: Download, Quality, Training Summary
  - Right: Configuration, Lineage, Actions

**Success:** Complete model artifacts page loads

---

## Section 5.2: Download Section

### Test 50: View Download Options
**What to test:** Download interface

**Steps:**
1. Find the Download Section (should be prominent, blue border)
2. Examine all information

**What you should see:**
- ‚úÖ Blue highlighted card (most prominent on page)
- ‚úÖ Download icon
- ‚úÖ Title: "Download LoRA Adapter"
- ‚úÖ Description: "Ready-to-use LoRA adapter..."
- ‚úÖ **Large Download Button:**
  - Blue/primary color
  - "Download LoRA Adapter (246 MB)"
  - Download icon
- ‚úÖ **Files Included List:**
  - `adapter_model.bin` (246 MB)
  - `adapter_config.json` (2 KB)
- ‚úÖ **Secondary Action:**
  - "Download Training Logs" link

**Success:** Download section is clear and prominent

---

### Test 51: Download LoRA Adapter
**What to test:** Adapter download process

**Steps:**
1. Click the "Download LoRA Adapter (246 MB)" button
2. Watch the download process

**What you should see:**
- ‚úÖ Button changes to loading state
- ‚úÖ Progress bar appears
- ‚úÖ Percentage increases: "45%... 67%... 89%... 100%"
- ‚úÖ Success state appears:
  - Green background
  - Checkmark icon
  - "Download complete! adapter_model.bin (246 MB)"
- ‚úÖ Toast notification: "Download Complete! üéâ"
- ‚úÖ Small confetti animation
- ‚úÖ Success state visible for 3 seconds

**Success:** Download simulates with progress and confirmation

---

### Test 52: Download Training Logs
**What to test:** Secondary download option

**Steps:**
1. Click "Download Training Logs" link

**What you should see:**
- ‚úÖ Console message or toast (this is a placeholder)
- ‚úÖ Indication that logs would download
- ‚úÖ (In real app, logs file would download)

**Success:** Training logs download option is available

---

## Section 5.3: Quality Metrics

### Test 53: View Quality Rating
**What to test:** Overall quality assessment

**Steps:**
1. Find the "Quality Metrics" card
2. Examine the quality rating

**What you should see:**
- ‚úÖ **Star Rating:** ‚≠ê‚≠ê‚≠ê‚≠ê (4 out of 5 stars filled)
- ‚úÖ **Quality Label:** "Good" badge
- ‚úÖ **Description:** "Strong performance, suitable for most use cases"
- ‚úÖ Color-coded (blue for "Good")

**Success:** Quality rating is prominently displayed with context

---

### Test 54: View Validation Loss Metric
**What to test:** Validation loss with context

**Steps:**
1. In Quality Metrics card, find Validation Loss section
2. Examine all information

**What you should see:**
- ‚úÖ **Metric Name:** "Validation Loss"
- ‚úÖ **Info Icon:** Hoverable for explanation
- ‚úÖ **Status Badge:** "Good" or "Excellent" (green/blue)
- ‚úÖ **Value:** 0.3120 (large, bold)
- ‚úÖ **Context Text:** "Good - acceptable loss" or similar
- ‚úÖ **Explanation:** "Lower is better. Values below 0.5 indicate good performance."

**Success:** Validation loss shown with helpful context

---

### Test 55: Hover Info Icons
**What to test:** Metric explanations

**Steps:**
1. Hover over the info icon (‚ÑπÔ∏è) next to "Validation Loss"
2. Try the same for "Perplexity"

**What you should see:**
- ‚úÖ Tooltip appears on hover
- ‚úÖ **Validation Loss tooltip:**
  - "Measures how well the model performs on unseen data"
  - "Lower is better"
  - "Values below 0.5 indicate good performance"
- ‚úÖ **Perplexity tooltip:**
  - "Measures model uncertainty in predictions"
  - "Lower is better"
  - "Values below 2.0 indicate good language modeling"

**Success:** Info tooltips provide clear explanations

---

### Test 56: View Perplexity Metric
**What to test:** Perplexity display

**Steps:**
1. Find the Perplexity metric in Quality Metrics
2. Examine the display

**What you should see:**
- ‚úÖ **Metric Name:** "Perplexity"
- ‚úÖ **Info Icon:** (hover for explanation)
- ‚úÖ **Status Badge:** "Good" or "Excellent"
- ‚úÖ **Value:** 1.28 (large, bold)
- ‚úÖ **Context:** "Excellent - very low perplexity" or similar

**Success:** Perplexity metric clearly displayed

---

### Test 57: View Training Improvement
**What to test:** Progress indicator

**Steps:**
1. Find the "Training Improvement" section (green box)
2. Examine the improvement data

**What you should see:**
- ‚úÖ Green background box
- ‚úÖ Trending down icon
- ‚úÖ "Training Improvement" label
- ‚úÖ **Improvement Text:**
  - "Started at 1.2400"
  - "Ended at 0.3120"
  - "(75% improvement)"
- ‚úÖ Shows training was successful

**Success:** Improvement from start to finish is clear

---

## Section 5.4: Training Summary

### Test 58: View Training Summary Details
**What to test:** Complete training information

**Steps:**
1. Find the "Training Summary" card
2. Examine all displayed information

**What you should see:**
- ‚úÖ Card Title: "Training Summary"
- ‚úÖ "View Full Training" button (link to P04)
- ‚úÖ **Completion Info:**
  - Green checkmark
  - "Training Completed"
  - Date and time
- ‚úÖ **Stats Grid (4 items):**
  - **Duration:** "11h 28m"
  - **Total Cost:** "$47.23" with estimate "$45-55"
  - **GPU Used:** "H100 PCIe 80GB" with "Spot" badge
  - **Progress:** "2,000 / 2,000 steps" and "3 / 3 epochs"
- ‚úÖ **Cost Comparison:**
  - Green box: "‚úì Cost within estimate (86% of max)"
  - OR Yellow box if exceeded

**Success:** Complete training summary with all key metrics

---

### Test 59: Navigate to Training Job
**What to test:** Link back to P04

**Steps:**
1. Click "View Full Training" button in Training Summary

**What you should see:**
- ‚úÖ Toast notification: "Navigating to training job..."
- ‚úÖ Console message showing target URL
- ‚úÖ (In real app, would navigate to P04 with job details)

**Success:** Link to training job (P04) is functional

---

## Section 5.5: Configuration Reference

### Test 60: View Training Configuration Used
**What to test:** Configuration details from P03

**Steps:**
1. Find the "Training Configuration" card (right sidebar)
2. Examine all settings

**What you should see:**
- ‚úÖ Settings icon
- ‚úÖ Card title: "Training Configuration"
- ‚úÖ "View Full Config" button
- ‚úÖ **Preset Badge:** "Balanced Preset" (blue)
- ‚úÖ **Key Hyperparameters Grid:**
  - LoRA Rank (r): 16
  - LoRA Alpha (Œ±): 32
  - Dropout: 0.05
  - Batch Size: 4
- ‚úÖ **Learning Rate:** "2e-4" with "Cosine Schedule" badge
- ‚úÖ **Epochs:** 3 (blue highlighted box)

**Success:** All training configuration parameters displayed

---

### Test 61: View Full Configuration
**What to test:** Link to P03

**Steps:**
1. Click "View Full Config" button

**What you should see:**
- ‚úÖ Toast notification: "Opening configuration..."
- ‚úÖ Console message showing navigation intent
- ‚úÖ (In real app, would open P03 in read-only mode)

**Success:** Link to view configuration (P03) is functional

---

## Section 5.6: Dataset Lineage

### Test 62: View Source Dataset Information
**What to test:** Dataset lineage tracking

**Steps:**
1. Find the "Dataset Lineage" card (right sidebar)
2. Examine all lineage information

**What you should see:**
- ‚úÖ Database icon
- ‚úÖ Card title: "Dataset Lineage"
- ‚úÖ "View Dataset" button
- ‚úÖ **Dataset Name:** "Healthcare Consultant Conversations" (clickable link)
- ‚úÖ **Training Pairs:** "1,567" with file icon
- ‚úÖ **Consultant Profile:**
  - User icon
  - Name: "Elena Morales"
  - Title: "CFP"
- ‚úÖ **Vertical:** "Healthcare" (blue box with briefcase icon)
- ‚úÖ **Scaffolding Coverage:**
  - Persona Coverage: 87% (progress bar)
  - Arc Coverage: 92% (progress bar)

**Success:** Complete dataset lineage is traceable

---

### Test 63: View Lineage Path
**What to test:** Pipeline visualization

**Steps:**
1. Scroll to bottom of Dataset Lineage card
2. Find "Complete Lineage Path"

**What you should see:**
- ‚úÖ Breadcrumb-style path:
  - **Dataset** (gray, clickable)
  - ‚Üí arrow
  - **Configuration** (gray)
  - ‚Üí arrow
  - **Training** (gray)
  - ‚Üí arrow
  - **Model Artifact** (blue, current)
- ‚úÖ Each step is visually separated
- ‚úÖ Current step highlighted

**Success:** Complete pipeline path is visualized

---

### Test 64: Navigate to Source Dataset
**What to test:** Link back to P02

**Steps:**
1. Click "View Dataset" button OR click the dataset name link
2. Watch the response

**What you should see:**
- ‚úÖ Toast notification: "Navigating to dataset..."
- ‚úÖ Console message showing target URL
- ‚úÖ (In real app, would navigate to P02 dataset detail)

**Success:** Link to source dataset (P02) is functional

---

## Section 5.7: Model Actions

### Test 65: View Available Actions
**What to test:** Model lifecycle management

**Steps:**
1. Find the "Model Actions" card (right sidebar)
2. Examine all action buttons

**What you should see (4 action buttons):**
- ‚úÖ **Test Model:**
  - Flask icon
  - "Test Model" text
  - Enabled (for Stored/Testing status)
- ‚úÖ **Deploy to Production:**
  - Rocket icon
  - "Deploy to Production" text
  - Enabled (if not already deployed)
- ‚úÖ **Archive:**
  - Archive icon
  - "Archive Model" text
  - Enabled (if not already archived)
- ‚úÖ **Delete:**
  - Trash icon
  - "Delete Model" text
  - Red text color
  - Always enabled

**Info Box:**
- ‚úÖ Note about archiving vs deleting

**Success:** All lifecycle actions are available

---

### Test 66: Test Model (Coming Soon)
**What to test:** Test model action

**Steps:**
1. Click "Test Model" button

**What you should see:**
- ‚úÖ Alert popup appears
- ‚úÖ Message: "Test Model feature coming soon!"
- ‚úÖ Description: "This will launch an inference interface where you can test the LoRA adapter with sample prompts."
- ‚úÖ OK button to dismiss

**Success:** Test model shows coming soon notice

---

### Test 67: Deploy to Production
**What to test:** Production deployment

**Steps:**
1. Click "Deploy to Production" button
2. Watch the response

**What you should see:**
- ‚úÖ Status badge changes from "Stored" to "Production" (green)
- ‚úÖ Success toast: "Model Deployed to Production! üöÄ"
- ‚úÖ Description: "Your LoRA model is now live and ready for inference"
- ‚úÖ Confetti animation üéâ
- ‚úÖ "Deploy to Production" button becomes disabled
- ‚úÖ Button shows "(Already deployed)" label

**Success:** Model status updates to Production with celebration

---

### Test 68: Open Archive Confirmation
**What to test:** Archive modal

**Steps:**
1. Click "Archive Model" button
2. Examine the confirmation dialog

**What you should see:**
- ‚úÖ Modal dialog opens
- ‚úÖ Archive icon (amber/orange)
- ‚úÖ Title: "Archive Model"
- ‚úÖ Description: "Are you sure you want to archive this model?"
- ‚úÖ **Model Summary:**
  - Model name
  - Status change: "production" ‚Üí "archived"
- ‚úÖ **Info Box:**
  - Amber background
  - "‚ÑπÔ∏è Info:" prefix
  - Explanation: Archived models not available for deployment but can be restored
  - Files remain in storage
- ‚úÖ **Buttons:**
  - "Cancel" (outline)
  - "Archive Model" (amber/orange, primary)

**Success:** Archive confirmation shows impact clearly

---

### Test 69: Confirm Archiving
**What to test:** Actually archiving the model

**Steps:**
1. In archive modal, click "Archive Model" button
2. Watch the process

**What you should see:**
- ‚úÖ Modal closes
- ‚úÖ Status badge changes to "Archived" (amber)
- ‚úÖ Toast notification: "Model Archived"
- ‚úÖ Description: "Model moved to archived status. You can restore it anytime."
- ‚úÖ Some action buttons become disabled

**Success:** Model successfully archived

---

### Test 70: Open Delete Confirmation
**What to test:** Delete modal with safety check

**Steps:**
1. Click "Delete Model" button (red)
2. Examine the confirmation dialog

**What you should see:**
- ‚úÖ Modal dialog opens
- ‚úÖ Red warning icon
- ‚úÖ Title: "Delete Model Permanently"
- ‚úÖ Description: "This action cannot be undone..."
- ‚úÖ **Warning Box (red):**
  - Alert icon
  - "Warning: Permanent Deletion" title
  - List of consequences:
    - Model files permanently deleted
    - Training history preserved
    - Action cannot be reversed
    - Need to retrain to recreate
- ‚úÖ **Confirmation Input:**
  - Label: "Type the model name to confirm"
  - Shows model name to type
  - Text input field
- ‚úÖ **Buttons:**
  - "Cancel" (outline)
  - "Delete Permanently" (red, destructive, DISABLED initially)

**Success:** Delete modal shows severe warnings and requires confirmation

---

### Test 71: Type Model Name for Deletion
**What to test:** Delete safety mechanism

**Steps:**
1. In delete modal, try clicking "Delete Permanently" (should be disabled)
2. Type the wrong name in the input field
3. Type the correct model name (shown above the input)
4. Watch the button state

**What you should see:**
- ‚úÖ Button disabled when input is empty
- ‚úÖ Button disabled when name doesn't match
- ‚úÖ Button **enabled** when exact name is typed
- ‚úÖ No other validation

**Success:** Must type exact name to enable delete

---

### Test 72: Confirm Deletion
**What to test:** Actually deleting the model

**Steps:**
1. With correct name typed, click "Delete Permanently"
2. Watch the process

**What you should see:**
- ‚úÖ Modal closes
- ‚úÖ Toast notification: "Model Deleted"
- ‚úÖ Description: "Model files have been permanently removed from storage"
- ‚úÖ Page begins to navigate away (simulated)
- ‚úÖ Console message about navigation
- ‚úÖ (In real app, would return to models list)

**Success:** Model deleted with confirmation

---

## Section 5.8: Version History

### Test 73: Show Version History
**What to test:** Version comparison feature

**Steps:**
1. Click "Show Version History" button (top-right of page)
2. Wait for Version History section to appear

**What you should see:**
- ‚úÖ New "Version History" card appears below other cards
- ‚úÖ Card title: "Version History"
- ‚úÖ Badge showing version count (e.g., "3 versions")
- ‚úÖ **Three version cards** (or however many exist):
  - Version 3 (most recent)
  - Version 2 (current - highlighted)
  - Version 1 (oldest)

**Success:** Version history section displays

---

### Test 74: Examine Version Cards
**What to test:** Version comparison information

**Steps:**
1. Look at each version card in the history
2. Compare information across versions

**What you should see on each version card:**
- ‚úÖ **Version Number:** "Version 3", "Version 2", etc.
- ‚úÖ **Current Badge:** Blue "Current" badge on active version
- ‚úÖ **Creation Date:** (with calendar icon)
- ‚úÖ **Star Rating:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (1-5 stars)
- ‚úÖ **Statistics Grid:**
  - Preset: "Aggressive", "Balanced", or "Conservative" badge
  - Validation Loss: e.g., "0.2890"
  - Cost: e.g., "$89.45"
  - File Size: e.g., "512 MB"
- ‚úÖ **View Button:** "View Version" (not on current version)

**Success:** All versions show comparable information

---

### Test 75: Compare Version Quality
**What to test:** Understanding version differences

**Steps:**
1. Compare star ratings across versions
2. Compare validation losses
3. Compare costs

**What you should notice:**
- ‚úÖ **Version 3 (Aggressive):**
  - 5 stars (Excellent)
  - Lowest loss (0.289)
  - Highest cost ($89.45)
  - Largest file (512 MB)
- ‚úÖ **Version 2 (Balanced) - CURRENT:**
  - 4 stars (Good)
  - Medium loss (0.312)
  - Medium cost ($47.23)
  - Medium file (246 MB)
- ‚úÖ **Version 1 (Conservative):**
  - 2 stars (Poor)
  - Highest loss (0.487)
  - Lowest cost ($28.76)
  - Smallest file (128 MB)

**Success:** You can compare quality vs cost tradeoffs

---

### Test 76: Switch to Different Version
**What to test:** Viewing other versions

**Steps:**
1. Click "View Version" button on Version 3 (Aggressive)
2. Watch the page update

**What you should see:**
- ‚úÖ Page content updates
- ‚úÖ Toast: "Version Loaded - Viewing version: Healthcare-Aggressive-20241210"
- ‚úÖ All cards update to show Version 3 data:
  - Model name changes
  - Status may be "Production" (green)
  - Quality rating: 5 stars
  - Different metrics
  - Different configuration
- ‚úÖ Version History updates:
  - Version 3 now has "Current" badge
  - Version 2 now has "View Version" button

**Success:** Can switch between versions and see different data

---

### Test 77: Hide Version History
**What to test:** Toggling version display

**Steps:**
1. Click "Hide Version History" button (top-right)
2. Watch the section

**What you should see:**
- ‚úÖ Version History card smoothly disappears
- ‚úÖ Button text changes to "Show Version History"
- ‚úÖ Other cards remain unchanged

**Success:** Version history is toggleable

---

## Section 5.9: Pipeline Completion

### Test 78: View Pipeline Completion Banner
**What to test:** Completion celebration

**Note:** This appears when model status is "Stored" (not Production/Archived)

**Steps:**
1. If model is Stored status, scroll to bottom of page
2. Look for the completion banner

**What you should see:**
- ‚úÖ Large banner with gradient background (blue to purple)
- ‚úÖ Blue border
- ‚úÖ üéØ Target emoji icon (large)
- ‚úÖ **Title:** "Training Pipeline Complete!"
- ‚úÖ **Description:**
  - "You've successfully completed the full training pipeline:"
  - "Dataset ‚Üí Configuration ‚Üí Training ‚Üí Model Artifact"
  - "Your trained LoRA adapter is ready to use."
- ‚úÖ **Action Buttons:**
  - "Deploy to Production" (blue, primary)
  - "Train Another Model" (outline, secondary)

**Success:** Completion banner celebrates finishing the full pipeline

---

### Test 79: Deploy from Completion Banner
**What to test:** Quick deploy action

**Steps:**
1. Click "Deploy to Production" button in completion banner

**What you should see:**
- ‚úÖ Same result as Test 67 (Deploy to Production)
- ‚úÖ Status changes to Production
- ‚úÖ Confetti celebration
- ‚úÖ Success toast

**Success:** Can deploy directly from completion banner

---

### Test 80: Train Another Model
**What to test:** Return to datasets

**Steps:**
1. Click "Train Another Model" button in completion banner

**What you should see:**
- ‚úÖ Toast: "Navigating to dataset..."
- ‚úÖ Console shows navigation to datasets
- ‚úÖ (In real app, would return to P02 to start new training)

**Success:** Can restart the training pipeline

---

# COMPREHENSIVE CHECKLIST

## P01 - Dashboard Shell ‚úÖ
- [ ] View main dashboard layout
- [ ] Navigate all sidebar items (Dashboard, Datasets, Training, Models)
- [ ] View active training indicator
- [ ] View cost tracker
- [ ] View notifications panel
- [ ] Access user profile menu
- [ ] Use breadcrumb navigation

## P02 - Dataset Management ‚úÖ
- [ ] Access dataset management page
- [ ] View all dataset cards
- [ ] Filter datasets by status and vertical
- [ ] View dataset details modal
- [ ] Examine scaffolding analysis
- [ ] View sample conversation pairs
- [ ] Close dataset modal
- [ ] Start training from dataset

## P03 - Training Configurator ‚úÖ
- [ ] View configuration page layout
- [ ] Examine all three presets (Conservative, Balanced, Aggressive)
- [ ] Switch between presets
- [ ] View cost estimate updates
- [ ] Expand advanced settings
- [ ] Adjust hyperparameters (LoRA Rank, Learning Rate, Epochs, etc.)
- [ ] View hyperparameter tooltips
- [ ] Collapse advanced settings
- [ ] View cost estimation breakdown
- [ ] Change GPU instance type (Spot/On-Demand)
- [ ] View validation checklist
- [ ] Trigger validation warnings
- [ ] Open launch confirmation modal
- [ ] Launch training job

## P04 - Training Monitor ‚úÖ
- [ ] View training monitor dashboard
- [ ] View overall progress header
- [ ] Monitor progress changes
- [ ] View all four training stages
- [ ] View active stage substatus
- [ ] View loss curve graph
- [ ] Interact with loss curve (hover tooltips)
- [ ] Export loss curve
- [ ] View all training metrics
- [ ] Understand metric trends
- [ ] View metrics update notice
- [ ] View real-time cost tracking
- [ ] Interpret cost progress bar
- [ ] View cost warnings (if applicable)
- [ ] Manual refresh metrics
- [ ] Open cancel job modal
- [ ] Select cancellation reason
- [ ] Confirm cancellation OR cancel without confirming
- [ ] View training completion state
- [ ] Navigate to model artifacts

## P05 - Model Artifacts ‚úÖ
- [ ] View model artifacts page
- [ ] View download options
- [ ] Download LoRA adapter (with progress)
- [ ] Download training logs
- [ ] View quality rating (stars)
- [ ] View validation loss metric
- [ ] Hover info icons for explanations
- [ ] View perplexity metric
- [ ] View training improvement
- [ ] View training summary details
- [ ] Navigate to training job (P04)
- [ ] View configuration used
- [ ] View full configuration (P03)
- [ ] View source dataset information
- [ ] View lineage path
- [ ] Navigate to source dataset (P02)
- [ ] View all model actions
- [ ] Test "Test Model" (coming soon)
- [ ] Deploy to production
- [ ] Open archive confirmation
- [ ] Confirm archiving
- [ ] Open delete confirmation
- [ ] Type model name for deletion
- [ ] Confirm deletion
- [ ] Show version history
- [ ] Examine version cards
- [ ] Compare version quality
- [ ] Switch to different version
- [ ] Hide version history
- [ ] View pipeline completion banner
- [ ] Deploy from completion banner
- [ ] Start training another model

---

# WORKFLOW TESTING SUMMARY

You have now tested the **complete LoRA Training Infrastructure workflow**:

## The Full Journey:
1. **P01**: Started at the dashboard and navigated the interface
2. **P02**: Selected a dataset for training
3. **P03**: Configured training with presets and hyperparameters
4. **P04**: Monitored training progress in real-time
5. **P05**: Downloaded and managed the trained model

## Total Features Tested: **80+ functional requirements**

## Mock Data Used:
- **Dataset**: Healthcare Consultant Conversations (1,567 pairs)
- **Configuration**: Balanced preset (LoRA rank 16, 3 epochs)
- **Training**: Simulated 11h 28m training job
- **Cost**: $47.23 (within $45-55 estimate)
- **Model**: 4-star quality rating, 0.312 validation loss

---

# TROUBLESHOOTING

## If something doesn't work:

### Modal won't open:
- Refresh the page
- Check browser console for errors
- Try clicking the button again

### Progress not updating:
- Click manual "Refresh" button
- Wait 60 seconds for auto-update
- Check that status is "running"

### Navigation not working:
- Look for console messages (they show where navigation would go)
- In demo mode, some navigation is simulated
- Check breadcrumbs to confirm current location

### Can't see all features:
- Make sure you're following the tutorial sequence
- Some features only appear in certain states (e.g., completion banner only when status is "Stored")
- Try different demo states by refreshing and selecting different options

---

# CONGRATULATIONS! üéâ

You have successfully tested every major feature of the LoRA Training Infrastructure application. You've gone through the complete workflow from dataset selection to trained model artifact, testing all functionality along the way.

The application is ready for the next phase of development where these mock features will be connected to real backend systems.
