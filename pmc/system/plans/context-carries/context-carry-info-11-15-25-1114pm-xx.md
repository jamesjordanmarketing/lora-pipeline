# Context Carryover: LoRA Pipeline Module - RunPod Infrastructure Setup in Progress

## ðŸ“Œ Active Development Focus

**Primary Task**: LoRA Training Pipeline Implementation - RunPod GPU Infrastructure Setup (Section E04.5)

### Current Status: RunPod Infrastructure Setup Phase (December 28, 2025)

Sections E01-E03 are **deployed to production** with bug fixes applied. We are now in the **RunPod Infrastructure Setup** phase (Section E04.5) preparing the GPU training worker before implementing Section E04 (Training Execution).

**Implementation Status**: ðŸ”§ RUNPOD INFRASTRUCTURE IN PROGRESS  
**Project ID**: hqhtbxlgzysfbekexwku  
**Environment**: 
- E01-E03: Deployed to Vercel production (December 27, 2025)
- E04.5: RunPod infrastructure setup (manual steps + Docker worker code needed)

---

## âœ… What Was Accomplished in This Session (December 28, 2025)

This session focused on **Section E04.5: RunPod Infrastructure Setup** - preparing the GPU training infrastructure before implementing Section E04 (Training Execution).

### Session Overview

**Purpose**: Set up RunPod serverless GPU infrastructure to execute LoRA training jobs created by Section E03.

**Approach**: Manual RunPod setup (network volume + model download) + Docker worker implementation

**Duration**: ~8 hours (extended troubleshooting for model download)

---

## ðŸ”§ Section E04.5: RunPod Infrastructure Setup Progress

### What This Section Does

Section E04.5 is a **prerequisite infrastructure setup** for Section E04 (Training Execution). It prepares the GPU environment where training jobs will actually execute.

**Key Components**:
1. **RunPod Network Volume** - Persistent storage for the Qwen3-Next-80B-A3B-Instruct model (~84GB)
2. **Model Download** - Pre-cache model weights to avoid re-downloading on each training run
3. **Docker Worker** - Containerized training worker with RunPod serverless handler
4. **RunPod Serverless Endpoint** - API endpoint for submitting training jobs from Supabase Edge Function

### Progress Summary

#### âœ… Phase 1: Network Volume & Model Download (COMPLETE)

**Network Volume Created**:
- Name: `qwen-model-cache`
- Size: **240GB** (originally 200GB, increased after disk space issues)
- Datacenter: US-CA-2
- Mount point: `/workspace` (NOT `/runpod-volume` as initially documented)

**Model Downloaded**:
- Model: `Qwen/Qwen3-Next-80B-A3B-Instruct` (instruction-tuned version)
- Size: ~84GB actual (specification said 80GB)
- Location: `/workspace/models/Qwen3-Next-80B-A3B-Instruct`
- Status: âœ… Download complete and verified

**Issues Encountered & Resolved**:

1. **Wrong Model Name (404 Error)**
   - Error: Repository not found for `Qwen/Qwen3-Next-80B-A3B`
   - Solution: Used correct name `Qwen/Qwen3-Next-80B-A3B-Instruct`
   - Reasoning: Instruction-tuned version needed for training tasks

2. **Bash Quote Escaping Issues**
   - Error: Python inline commands failing with nested quotes
   - Solution: Used heredoc format `cat << 'EOF'` to avoid quote escaping
   - Pattern: More reliable for multi-line Python scripts in bash

3. **Disk Space Exhaustion**
   - Error: "No space left on device" at 21GB/84GB
   - Root Cause: Volume not mounted, using 20GB container disk instead
   - Discovery: Pod was using `/workspace`, not `/runpod-volume` as documented
   - Solution: Corrected all paths in instructions from `/runpod-volume/` to `/workspace/`

4. **Volume Size Insufficient**
   - Error: 200GB volume too small for 84GB model + cache overhead
   - Solution: Increased volume to 240GB
   - Calculation: ~2.5x model size needed (84GB model + HuggingFace cache)

5. **Unauthenticated Download**
   - Issue: Forgot HF token parameter, slower download speeds
   - Solution: Provided resume command with token
   - Outcome: Download completed successfully

**Key Learning**: Always verify volume mount points with `df -h` before downloading large files. RunPod uses `/workspace` by default for network volumes, not `/runpod-volume`.

**Instructions File Updated**: All corrections documented in `04f-pipeline-build-section-E04.5-runpod-instructions.md`

#### â³ Phase 2: Docker Worker Code Generation (IN PROGRESS)

**Directory Created**: `C:\Users\james\Master\BrightHub\BRun\brightrun-trainer\` (outside lora-pipeline repo)

**Files Created** (Empty, awaiting code):
1. `handler.py` - RunPod serverless handler
2. `train_lora.py` - QLoRA training script
3. `Dockerfile` - Container definition
4. `requirements.txt` - Python dependencies
5. `status_manager.py` - Job status tracking (mentioned in instructions)

**Current State**: Empty files created, waiting for code generation

**Next Step**: Generate production-ready code for all 5 files

**Code Generation Approach**:
- **Option A (AI Agent in VS Code)**: Ask your AI agent: "Generate 5 production-ready Docker worker files in C:\\Users\\james\\Master\\BrightHub\\BRun\\brightrun-trainer\\ using the specification between the ==== and ++++ markers in Section 2 of this file. Create: handler.py (RunPod serverless handler), train_lora.py (QLoRA training with 4-bit quantization), Dockerfile (linux/amd64), requirements.txt (pinned versions), and status_manager.py (job status tracking). Use model path /runpod-volume/models/Qwen3-Next-80B-A3B-Instruct."
- **Option B (Web Interface)**: Copy the DOCKER WORKER SPECIFICATION from Section 2 of instructions file (between ==== and ++++ markers, lines ~320-550) and paste into ChatGPT-4 or Claude web interface

#### â¸ï¸ Phase 3-6: Pending (After Docker Worker Code is Complete)

Remaining phases once Docker worker code is generated:

- **Phase 3**: Build Docker image for linux/amd64 platform
- **Phase 4**: Push image to Docker Hub
- **Phase 5**: Create RunPod serverless template with environment variables
- **Phase 6**: Deploy serverless endpoint with network volume attached
- **Phase 7**: Configure application (.env.local + Supabase Edge Function secrets)

---

## ðŸ“¦ Deployment Status & Bug Fixes (December 27, 2025)

### Sections E01-E03 Deployed to Production

**Deployment Date**: December 27, 2025  
**Environment**: Vercel production + Supabase (project: hqhtbxlgzysfbekexwku)

### Critical Bug Fixes Applied Before Deployment

During deployment testing, discovered 3 critical bugs that would have blocked production. All fixed:

#### Bug 1: Toast Import Error (useTrainingConfig.ts)
**Error**: `Module '"sonner"' has no exported member 'toast'`  
**Root Cause**: Incorrect import syntax for sonner library  
**Fix**: Changed from `import { toast } from 'sonner'` to `import { toast } from 'sonner'` with proper default export handling  
**File**: `src/hooks/useTrainingConfig.ts`  
**Status**: âœ… Fixed

#### Bug 2: Missing Await (jobs/estimate/route.ts)
**Error**: Type 'Promise<SupabaseClient>' missing await  
**Root Cause**: `createServerSupabaseClient()` is async but wasn't awaited  
**Fix**: Added `await` keyword: `const supabase = await createServerSupabaseClient()`  
**File**: `src/app/api/jobs/estimate/route.ts`  
**Status**: âœ… Fixed

#### Bug 3: React Query v5 API Change (useTrainingConfig.ts)
**Error**: `refetchInterval` callback signature changed in React Query v5  
**Root Cause**: Using v4 API pattern in v5 environment  
**Old Code**: `refetchInterval: (data) => data && (data.status === 'running' || ...) ? 5000 : false`  
**New Code**: `refetchInterval: (query) => query.state.data && (query.state.data.status === 'running' || ...) ? 5000 : false`  
**File**: `src/hooks/useTrainingConfig.ts` (useTrainingJob hook)  
**Status**: âœ… Fixed

**Result**: All TypeScript compilation clean, deployment successful

---

## ðŸ—‚ï¸ Documentation Created This Session

### 1. Bug Fix Carryover Document
**File**: `context-carry-info-11-15-25-1114pm-ww.md`  
**Purpose**: Document bug fixes and deployment status for next agent  
**Content**: 
- Detailed bug descriptions and solutions
- Deployment verification steps
- Testing recommendations
- Section E04 preparation notes

### 2. Updated RunPod Instructions
**File**: `04f-pipeline-build-section-E04.5-runpod-instructions.md`  
**Updates Applied**:
- Corrected model name: `Qwen/Qwen3-Next-80B-A3B-Instruct`
- Fixed all paths from `/runpod-volume/` to `/workspace/`
- Updated volume size recommendation: 200GB â†’ 240GB minimum
- Added troubleshooting entries for all issues encountered
- Clarified code generation options (Method A vs Method B)
- Added verified download command with heredoc format

---

## ðŸ“Š Current Project State

### Section E01: Foundation & Authentication
**Status**: âœ… DEPLOYED TO PRODUCTION
- Database schema (6 tables)
- TypeScript types
- Storage buckets (3 buckets)
- RLS policies
- Authentication patterns

### Section E02: Dataset Management
**Status**: âœ… DEPLOYED TO PRODUCTION (December 26, 2025)
- Dataset upload with presigned URLs (up to 500MB)
- Background validation (Edge Function)
- Dataset management UI
- React Query hooks
- JSONL format validation

### Section E03: Training Configuration
**Status**: âœ… DEPLOYED TO PRODUCTION (December 27, 2025, with bug fixes)
- Cost estimation API (GPU pricing + duration calculation)
- Job creation API (with dataset validation)
- Training configuration UI with 3 presets (Fast, Balanced, Quality)
- Real-time cost updates (debounced to 500ms)
- React Query hooks with auto-polling

**Files**:
- `src/app/api/jobs/estimate/route.ts` - Cost calculation endpoint
- `src/app/api/jobs/route.ts` - Job creation and listing
- `src/hooks/useTrainingConfig.ts` - 4 React Query hooks
- `src/app/(dashboard)/training/configure/page.tsx` - Configuration form

### Section E03b: DATA-BRIDGE (Training Files Migration)
**Status**: âœ… DEPLOYED TO PRODUCTION (December 27, 2025)
- Migration API to import training_files into datasets
- Storage path mapping (training-files bucket â†’ datasets table)
- Status flag setting (status='ready', training_ready=true)
- Token calculation for existing files
- UI for viewing and importing training files

### Section E04.5: RunPod Infrastructure Setup
**Status**: ðŸ”§ IN PROGRESS (December 28, 2025 - THIS SESSION)
- âœ… Network volume created (240GB, US-CA-2)
- âœ… Model downloaded (84GB, Qwen3-Next-80B-A3B-Instruct)
- âœ… Volume mount path verified (/workspace)
- âœ… Instructions file updated with corrections
- â³ Docker worker directory created with empty files
- â¸ï¸ Docker worker code generation (next step)
- â¸ï¸ Docker image build and push
- â¸ï¸ RunPod template creation
- â¸ï¸ Serverless endpoint deployment
- â¸ï¸ Application configuration

### Section E04: Training Execution & Monitoring
**Status**: â³ NOT STARTED (After E04.5 complete)
- Edge Function to process queued jobs
- GPU cluster integration (RunPod API)
- Training progress tracking
- Real-time status updates
- Job monitoring UI
- Job cancellation
- Cost tracking during training

---

## ðŸ”œ What's Ready for Implementation

### For Docker Worker Code Generation

The next agent needs to generate 5 Docker worker files with production-ready code:

**1. handler.py**
- Purpose: RunPod serverless handler
- Pattern: `runpod.serverless.start({"handler": handler})`
- Responsibilities:
  - Receive job input from RunPod API
  - Validate parameters (dataset_url, hyperparameters, gpu_config)
  - Call train_lora.py to execute training
  - Return job ID and status
  - Handle errors gracefully with descriptive messages

**2. train_lora.py**
- Purpose: LoRA training script with QLoRA (4-bit quantization)
- Base Model: Qwen/Qwen3-Next-80B-A3B-Instruct from `/runpod-volume/models/`
- Key Features:
  - Load model with BitsAndBytesConfig (4-bit, nf4, double quantization)
  - Configure LoRA adapters (PEFT library) with target modules: q_proj, k_proj, v_proj, o_proj, gate_proj, up_proj, down_proj
  - Download dataset from signed Supabase URL
  - Train with SFTTrainer (trl library)
  - Progress callbacks for status updates
  - Save adapter to temporary directory
  - Upload trained adapter to Supabase Storage (lora-models bucket)
  - Return metrics throughout training

**3. Dockerfile**
- Base Image: `runpod/pytorch:2.1.0-py3.10-cuda11.8.0`
- Dependencies: transformers, peft, accelerate, bitsandbytes, trl, runpod, supabase
- Platform: linux/amd64 (RunPod requirement)

**4. requirements.txt**
- Pin versions for reproducibility:
  - transformers>=4.36.0
  - peft>=0.7.0
  - accelerate>=0.25.0
  - bitsandbytes>=0.41.0
  - trl>=0.7.0
  - runpod>=1.6.0
  - supabase>=2.0.0

**5. status_manager.py**
- Purpose: Job status tracking utility
- Stores current job status in memory (per-worker state)
- Provides status retrieval
- Updates progress, metrics, and stage

**API Contract** (from Supabase Edge Function):

**Request Format**:
```json
{
  "job_id": "uuid-string",
  "dataset_url": "https://signed-supabase-url/dataset.jsonl",
  "hyperparameters": {
    "base_model": "Qwen/Qwen3-Next-80B-A3B-Instruct",
    "learning_rate": 0.0002,
    "batch_size": 8,
    "num_epochs": 5,
    "lora_rank": 16,
    "lora_alpha": 32,
    "lora_dropout": 0.1
  },
  "gpu_config": {
    "gpu_type": "H100",
    "num_gpus": 1,
    "gpu_memory_gb": 80,
    "cost_per_gpu_hour": 3.35
  },
  "callback_url": "https://project.supabase.co/functions/v1/training-callback"
}
```

**Status Response Format**:
```json
{
  "status": "running" | "completed" | "failed",
  "progress": 45.5,
  "current_epoch": 2,
  "current_step": 450,
  "stage": "training" | "saving" | "uploading",
  "metrics": {
    "training_loss": 1.234,
    "validation_loss": 1.456,
    "learning_rate": 0.0002,
    "throughput": 125.4,
    "gpu_utilization": 92.5,
    "gradient_norm": 0.5
  },
  "error_message": null
}
```

### For RunPod Deployment (After Code Generation)

Once Docker worker code is generated and tested:

**Docker Build Command**:
```bash
cd C:\Users\james\Master\BrightHub\BRun\brightrun-trainer
docker build --platform linux/amd64 -t yourdockerhub/brightrun-trainer:v1 .
docker push yourdockerhub/brightrun-trainer:v1
```

**RunPod Template Configuration**:
- Template Name: `BrightRun LoRA Trainer`
- Container Image: `yourdockerhub/brightrun-trainer:v1`
- Volume Mount Path: `/runpod-volume` (serverless uses different path than pods)
- Environment Variables:
  - `HF_HOME=/runpod-volume/.cache/huggingface`
  - `TRANSFORMERS_CACHE=/runpod-volume/models`
  - `MODEL_PATH=/runpod-volume/models/Qwen3-Next-80B-A3B-Instruct`
  - `SUPABASE_URL` and `SUPABASE_SERVICE_ROLE_KEY`

**RunPod Endpoint Configuration**:
- Endpoint Name: `brightrun-lora-trainer`
- GPU: A100 80GB (or H100 if available)
- Active Workers: 0 (auto-scaling)
- Max Workers: 2
- Execution Timeout: 43200 seconds (12 hours)
- Network Volume: `qwen-model-cache` (attached)

**Application Configuration** (after endpoint deployed):
- Update `.env.local`: `GPU_CLUSTER_API_URL` and `GPU_CLUSTER_API_KEY`
- Add secrets to Supabase Edge Function
- Deploy edge function: `supabase functions deploy process-training-jobs`

---

## ðŸŽ¯ NEXT AGENT: Critical Instructions

### âš ï¸ MANDATORY: Read This First

**DO NOT start implementing, fixing, or writing anything immediately.**

Your ONLY job right now is to:
1. âœ… Read and internalize ALL context files listed below
2. âœ… Understand the codebase architecture and patterns
3. âœ… Understand what has been implemented (E01-E03b)
4. âœ… Understand what is in progress (E04.5 RunPod setup)
5. âœ… **STOP and WAIT for explicit human instructions**

### PHASE A: Context Internalization (MANDATORY - 16-20 hours)

Read and understand ALL of the following before receiving any task instructions:

#### 1. Production Codebase (HIGHEST PRIORITY - START HERE)

**Directory**: `C:\Users\james\Master\BrightHub\BRun\lora-pipeline\src`

**Purpose**: Understand the existing Next.js + Supabase application architecture, patterns, and conventions.

**What to Study**:

- **API Routes** (`src/app/api/**/route.ts`):
  - Authentication patterns using `requireAuth()`
  - Response format: `{ success: true, data: ... }` or `{ error: '...', details: ... }`
  - Error handling and rollback logic
  - Supabase client usage (server-side)
  - RLS enforcement patterns
  - Zod validation schemas

- **React Hooks** (`src/hooks/*.ts`):
  - React Query patterns (`useQuery`, `useMutation`)
  - Cache invalidation strategies (`invalidateQueries`)
  - Toast notifications using `sonner` library (correct import: `import { toast } from 'sonner'`)
  - Error handling in hooks
  - TypeScript typing conventions
  - Debouncing patterns (`useDebounce`)

- **UI Components** (`src/components/**/*.tsx`):
  - Shadcn/ui component library usage
  - Tailwind CSS styling conventions
  - Loading states and skeletons
  - Empty states and error states
  - Responsive design patterns
  - Interactive form controls (sliders, selects)

- **Services** (`src/services/**/*.ts`):
  - Business logic separation
  - Service layer patterns
  - External API integrations (Claude API)
  - File upload/download handling

- **Types** (`src/lib/types/**/*.ts`):
  - TypeScript interface conventions
  - Zod schema validation patterns
  - Type inference from Zod schemas
  - Enum definitions

- **Supabase Integration** (`src/lib/supabase-*.ts`):
  - Server client creation: `createServerSupabaseClient()` **requires await**
  - Admin client for privileged operations
  - Authentication helpers: `requireAuth()`
  - Storage operations (presigned URLs)

**Time Investment**: 4-5 hours (critical - don't rush)

**Why This Matters**: Every new feature must follow these established patterns. Consistency is essential.

---

#### 2. Specification Files (Build Understanding)

**Read in this order**:

**A. Section E01: Foundation & Authentication**
- File: `04f-pipeline-build-section-E01-execution-prompts.md`
- Purpose: Database schema, TypeScript types, storage buckets, RLS policies
- Time: 1-2 hours

**B. Section E02: Dataset Management**
- File: `04f-pipeline-build-section-E02-execution-prompts.md`
- Purpose: Dataset upload, validation, management UI
- Time: 2 hours

**C. Section E03: Training Configuration**
- File: `04f-pipeline-build-section-E03-execution-prompts.md`
- Purpose: Cost estimation, job creation, configuration UI with presets
- Time: 3-4 hours

**D. Section E03b: DATA-BRIDGE**
- File: `04f-pipeline-build-section-E03b-DATA-BRIDGE-execution-prompts.md`
- Purpose: Migration from training_files to datasets
- Time: 1 hour

**E. Section E04.5: RunPod Infrastructure Setup**
- File: `04f-pipeline-build-section-E04.5-runpod-instructions.md`
- Purpose: GPU infrastructure setup, Docker worker specification
- Time: 2-3 hours
- **CRITICAL**: Read Section 2 (AUTONOMOUS AGENT PROMPT) carefully - this contains the Docker worker code specification

**F. Section E04: Training Execution (For Context Only)**
- File: `04f-pipeline-build-section-E04-execution-prompts.md` (if exists)
- Purpose: Understand what comes after E04.5
- Time: 2 hours
- **âš ï¸ DO NOT IMPLEMENT** - Only read for context

---

#### 3. Implementation Summary Files

**Read these to understand what was actually built**:

- `E01_IMPLEMENTATION_COMPLETE.md` - Foundation implementation details
- `E02_IMPLEMENTATION_SUMMARY.md` - Dataset management implementation
- `E03_IMPLEMENTATION_SUMMARY.md` - Training configuration implementation
- `context-carry-info-11-15-25-1114pm-ww.md` - Bug fixes and deployment notes

**Time Investment**: 2-3 hours

---

#### 4. RunPod Infrastructure Context (Current Work)

**Directory**: `C:\Users\james\Master\BrightHub\BRun\brightrun-trainer\`

**Current State**:
- Empty files created: handler.py, train_lora.py, Dockerfile, requirements.txt
- Model cached: /workspace/models/Qwen3-Next-80B-A3B-Instruct (84GB)
- Network volume: qwen-model-cache (240GB, US-CA-2)

**What Needs Code**:
All 5 Docker worker files need production-ready Python code based on the specification in Section 2 of `04f-pipeline-build-section-E04.5-runpod-instructions.md`

**Time Investment**: 1-2 hours

---

### PHASE B: STOP AND WAIT (MANDATORY)

**After completing Phase A (context internalization), you MUST STOP and WAIT for explicit human instructions.**

#### âŒ DO NOT Do Any of These:

- âŒ Start implementing Section E04 (Training Execution)
- âŒ Generate Docker worker code (wait for explicit instruction)
- âŒ Start implementing any new features
- âŒ Fix any bugs or issues you find
- âŒ Create any new files
- âŒ Modify any existing files
- âŒ Run any scripts or commands
- âŒ Make suggestions or recommendations
- âŒ Deploy anything to Vercel or Supabase
- âŒ "Improve" or "optimize" existing code
- âŒ Test the implementation
- âŒ Refactor any code
- âŒ Add comments or documentation
- âŒ Update dependencies
- âŒ Configure anything in RunPod Dashboard
- âŒ Build Docker images
- âŒ Push to Docker Hub

#### âœ… ONLY Do These:

- âœ… Read all files listed in Phase A
- âœ… Understand the codebase patterns in `src/`
- âœ… Understand Section E01 (database foundation)
- âœ… Understand Section E02 (dataset management)
- âœ… Understand Section E03 (training configuration with bug fixes)
- âœ… Understand Section E03b (DATA-BRIDGE migration)
- âœ… Understand Section E04.5 specification (RunPod setup)
- âœ… Understand Section E04 specification (for context only)
- âœ… Understand what was accomplished in this session (RunPod setup)
- âœ… Take notes on what you learned (mentally)
- âœ… Form questions for the human (if any)
- âœ… Confirm context internalization is complete
- âœ… **WAIT** for human to provide specific instructions

#### When Context Internalization is Complete:

Simply respond with:

```
Context internalization complete.

I have read and understood:
- Production codebase (src/ directory)
- Section E01: Database foundation (deployed)
- Section E02: Dataset management (deployed)
- Section E03: Training configuration (deployed with bug fixes)
- Section E03b: DATA-BRIDGE migration (deployed)
- Section E04.5: RunPod infrastructure specification (in progress)
- Section E04: Training execution specification (for context only)
- Current session work: RunPod network volume setup, model download, path corrections
- Docker worker code specification in Section E04.5

Current state:
- E01-E03b: Deployed to production (December 27, 2025)
- E04.5 Phase 1: Complete (network volume + model cached)
- E04.5 Phase 2: Empty Docker worker files created, awaiting code generation
- E04.5 Phases 3-6: Pending (Docker build, push, RunPod deployment, app config)

Waiting for human instructions on what to do next.

Total time invested in context internalization: ~16-20 hours
```

**Do NOT**:
- Make suggestions about what to do next
- Ask "Would you like me to..." questions
- Propose improvements or fixes
- Start analyzing code for issues

**Simply WAIT** for the human to tell you explicitly what task to perform next.

---

### Total Context Internalization Time: ~16-20 hours

This is intentional and necessary. Rushing through context leads to:
- Inconsistent code patterns
- Breaking existing functionality
- Misunderstanding requirements
- Needing to redo work later

**Take your time. Read carefully. Understand deeply.**

---

## ðŸ” Supabase Agent Ops Library (SAOL) Quick Reference

**Version:** 2.1 (Bug Fixes Applied - December 6, 2025)

### Setup & Usage

**Installation**: Already available in project
```bash
# SAOL is installed and configured
# Located in supa-agent-ops/ directory
```

**CRITICAL: You MUST use the Supabase Agent Ops Library (SAOL) for ALL database operations.**
Do not use raw `supabase-js` or PostgreSQL scripts. SAOL is safe, robust, and handles edge cases for you.

**Library Path:** supa-agent-ops
**Quick Start:** QUICK_START.md (READ THIS FIRST)
**Troubleshooting:** TROUBLESHOOTING.md

### Key Rules
1. **Use Service Role Key:** Operations require admin privileges. Ensure `SUPABASE_SERVICE_ROLE_KEY` is loaded.
2. **Run Preflight:** Always run `agentPreflight({ table })` before modifying data.
3. **No Manual Escaping:** SAOL handles special characters automatically.
4. **Parameter Flexibility:** SAOL accepts both `where`/`column` (recommended) and `filters`/`field` (backward compatible).

### Quick Reference: One-Liner Commands

**Note:** All examples updated for SAOL v2.1 with bug fixes applied.

```bash
# Query conversations (all columns)
cd "c:/Users/james/Master/BrightHub/BRun/lora-pipeline/supa-agent-ops" && node -e "require('dotenv').config({path:'../.env.local'});const saol=require('.');(async()=>{const r=await saol.agentQuery({table:'conversations',limit:5});console.log('Success:',r.success);console.log('Count:',r.data.length);console.log(JSON.stringify(r.data,null,2));})();"

# Check schema (Deep Introspection)
cd "c:/Users/james/Master/BrightHub/BRun/lora-pipeline/supa-agent-ops" && node -e "require('dotenv').config({path:'../.env.local'});const saol=require('.');(async()=>{const r=await saol.agentIntrospectSchema({table:'conversations',transport:'pg'});console.log(JSON.stringify(r,null,2));})();"

# Verify datasets table (Section E02)
cd "c:/Users/james/Master/BrightHub/BRun/lora-pipeline/supa-agent-ops" && node -e "require('dotenv').config({path:'../.env.local'});const saol=require('.');(async()=>{const r=await saol.agentIntrospectSchema({table:'datasets',transport:'pg'});console.log('Table exists:',r.success);if(r.success){console.log('Columns:',r.tables[0].columns.length);console.log('RLS Enabled:',r.tables[0].rlsEnabled);console.log('Policies:',r.tables[0].policies.length);}})();"

# Query datasets (Section E02)
cd "c:/Users/james/Master/BrightHub/BRun/lora-pipeline/supa-agent-ops" && node -e "require('dotenv').config({path:'../.env.local'});const saol=require('.');(async()=>{const r=await saol.agentQuery({table:'datasets',select:'id,name,status,training_ready,total_training_pairs',orderBy:[{column:'created_at',asc:false}],limit:10});console.log('Datasets:',r.data.length);r.data.forEach(d=>console.log('-',d.name,'/',d.status));})();"

# Verify training_jobs table (Section E03)
cd "c:/Users/james/Master/BrightHub/BRun/lora-pipeline/supa-agent-ops" && node -e "require('dotenv').config({path:'../.env.local'});const saol=require('.');(async()=>{const r=await saol.agentQuery({table:'training_jobs',select:'id,status,preset_id,progress,total_steps,estimated_total_cost',orderBy:[{column:'created_at',asc:false}],limit:5});console.log('Training jobs:',r.data.length);r.data.forEach(j=>console.log('-',j.id.slice(0,8),'/',j.status,'/',j.preset_id));})();"

# Verify notifications table (Section E03)
cd "c:/Users/james/Master/BrightHub/BRun/lora-pipeline/supa-agent-ops" && node -e "require('dotenv').config({path:'../.env.local'});const saol=require('.');(async()=>{const r=await saol.agentQuery({table:'notifications',select:'type,title,message,created_at',where:[{column:'type',operator:'eq',value:'job_queued'}],orderBy:[{column:'created_at',asc:false}],limit:5});console.log('Job queued notifications:',r.data.length);r.data.forEach(n=>console.log('-',n.title));})();"
```

### Common Queries

**Check conversations (specific columns, with filtering)**:
```bash
cd "c:/Users/james/Master/BrightHub/BRun/lora-pipeline/supa-agent-ops" && node -e "require('dotenv').config({path:'../.env.local'});const saol=require('.');(async()=>{const r=await saol.agentQuery({table:'conversations',select:'id,conversation_id,enrichment_status,title',where:[{column:'enrichment_status',operator:'eq',value:'completed'}],orderBy:[{column:'created_at',asc:false}],limit:10});console.log('Success:',r.success,'Count:',r.data.length);r.data.forEach(c=>console.log('-',c.conversation_id.slice(0,8),'/',c.enrichment_status));})();"
```

**Check training files**:
```bash
cd "c:/Users/james/Master/BrightHub/BRun/lora-pipeline/supa-agent-ops" && node -e "require('dotenv').config({path:'../.env.local'});const saol=require('.');(async()=>{const r=await saol.agentQuery({table:'training_files',select:'id,name,conversation_count,total_training_pairs,created_at',orderBy:[{column:'created_at',asc:false}],limit:5});console.log('Files:',r.data.length);r.data.forEach(f=>console.log('-',f.name,'(',f.conversation_count,'convs)'));})();"
```

**Check prompt templates (edge case tier)**:
```bash
cd "c:/Users/james/Master/BrightHub/BRun/lora-pipeline/supa-agent-ops" && node -e "require('dotenv').config({path:'../.env.local'});const saol=require('.');(async()=>{const r=await saol.agentQuery({table:'prompt_templates',select:'template_name,tier,emotional_arc_type',where:[{column:'tier',operator:'eq',value:'edge_case'}]});console.log('Edge case templates:',r.data.length);r.data.forEach(t=>console.log('-',t.template_name));})();"
```

**Check emotional arcs (edge case tier)**:
```bash
cd "c:/Users/james/Master/BrightHub/BRun/lora-pipeline/supa-agent-ops" && node -e "require('dotenv').config({path:'../.env.local'});const saol=require('.');(async()=>{const r=await saol.agentQuery({table:'emotional_arcs',select:'arc_key,name,tier',where:[{column:'tier',operator:'eq',value:'edge_case'}]});console.log('Edge case arcs:',r.data.length);r.data.forEach(a=>console.log('-',a.arc_key,'â†’',a.name));})();"
```

### SAOL Parameter Formats (Both Work)

**Recommended Format** (clear intent):
```javascript
const result = await saol.agentQuery({
  table: 'prompt_templates',
  select: ['template_name', 'tier', 'emotional_arc_type'],  // Array
  where: [{ column: 'tier', operator: 'eq', value: 'edge_case' }],  // where + column
  orderBy: [{ column: 'created_at', asc: false }]
});
```

**Backward Compatible Format**:
```javascript
const result = await saol.agentQuery({
  table: 'prompt_templates',
  select: 'template_name,tier,emotional_arc_type',  // String
  filters: [{ field: 'tier', operator: 'eq', value: 'edge_case' }],  // filters + field
  orderBy: [{ column: 'created_at', asc: false }]
});
```

---

## ðŸ“‹ Project Functional Context

### What This Application Does

**Bright Run LoRA Training Data Platform** - A Next.js 14 application that generates high-quality AI training conversations for fine-tuning large language models. The platform enables non-technical domain experts to transform proprietary knowledge into LoRA-ready training datasets and execute GPU training jobs.

**Core Capabilities**:
1. **Conversation Generation**: AI-powered generation using Claude API with predetermined field structure
2. **Enrichment Pipeline**: 5-stage validation and enrichment process for quality assurance
3. **Storage System**: File storage (Supabase Storage) + metadata (PostgreSQL)
4. **Management Dashboard**: UI for reviewing, downloading, and managing conversations
5. **Download System**: Export both raw (minimal) and enriched (complete) JSON formats
6. **LoRA Training Pipeline** (NEW):
   - **Section E02 (DEPLOYED)**: Dataset upload with presigned URLs (up to 500MB), background validation, dataset management
   - **Section E03 (DEPLOYED)**: Training job configuration with presets, cost estimation, job creation
   - **Section E03b (DEPLOYED)**: Training files to datasets migration bridge
   - **Section E04.5 (IN PROGRESS)**: RunPod GPU infrastructure setup (network volume + Docker worker)
   - **Section E04 (NEXT)**: Training execution, real-time monitoring, job management

### Core Workflow

```
User â†’ Generate Conversation â†’ Claude API â†’ Raw JSON Stored â†’
Enrichment Pipeline (5 stages) â†’ Enriched JSON Stored â†’
Dashboard View â†’ Download (Raw or Enriched) â†’ Combine Multiple JSON files into a full training file â†’
[E02] Upload to LoRA Pipeline â†’ Validate Dataset â†’
[E03] Configure Training Job (Presets + Cost Estimation) â†’ Create Job (status='queued') â†’
[E04.5] RunPod Infrastructure (GPU + Model Cache) â†’
[E04] Execute Training â†’ Monitor Progress â†’ Download Trained Model
```

### Technology Stack

- **Framework**: Next.js 14 (App Router)
- **Language**: TypeScript
- **Database**: Supabase (PostgreSQL)
- **Storage**: Supabase Storage (buckets: conversation-files, training-files, lora-datasets, lora-models)
- **AI**: Claude API (Anthropic) - `claude-sonnet-4-5-20250929`
- **Structured Outputs**: `anthropic-beta: structured-outputs-2025-11-13`
- **UI**: Shadcn/UI + Tailwind CSS
- **State Management**: React Query v5 (TanStack Query)
- **Deployment**: Vercel (frontend + API routes)
- **Edge Functions**: Supabase Edge Functions (Deno runtime)
- **GPU Training**: RunPod Serverless (A100/H100 GPUs)
- **Training Framework**: Transformers + PEFT + bitsandbytes (QLoRA 4-bit)

### Production Pipeline (SECTIONS E01-E03b DEPLOYED, E04.5 IN PROGRESS)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. SCAFFOLDING SELECTION                                    â”‚
â”‚    - Personas, Emotional Arcs, Training Topics              â”‚
â”‚    â†’ Stored in database tables                              â”‚
â”‚    âœ… Working for all tiers                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. CONVERSATION GENERATION (Claude API)                     â”‚
â”‚    â†’ conversation-generation-service.ts                     â”‚
â”‚    â†’ Output: Raw JSON with turns[]                          â”‚
â”‚    â†’ Stored in: conversation-files/{userId}/{id}/raw.json   â”‚
â”‚    âœ… Working for ALL tiers (template + edge_case)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. ENRICHMENT (Metadata Addition)                           â”‚
â”‚    â†’ enrichment-pipeline-orchestrator.ts                    â”‚
â”‚    â†’ conversation-enrichment-service.ts                     â”‚
â”‚    â†’ Output: Enriched JSON with training_pairs[]            â”‚
â”‚    â†’ Stored in: conversation-files/{userId}/{id}/enriched.jsonâ”‚
â”‚    âœ… Working                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. TRAINING FILE AGGREGATION                                â”‚
â”‚    â†’ training-file-service.ts                               â”‚
â”‚    â†’ Combines multiple enriched files into one              â”‚
â”‚    â†’ Output: Full JSON + JSONL in brightrun-lora-v4 format  â”‚
â”‚    â†’ Stored in: training-files/{fileId}/training.json       â”‚
â”‚    âœ… Working (create + add conversations)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. LORA DATASET MANAGEMENT (Section E02)                    â”‚
â”‚    â†’ POST /api/datasets (create + presigned URL)            â”‚
â”‚    â†’ Upload to lora-datasets bucket (direct S3)             â”‚
â”‚    â†’ POST /api/datasets/[id]/confirm (trigger validation)   â”‚
â”‚    â†’ Edge Function: validate-datasets (background)          â”‚
â”‚    â†’ Output: Validated dataset with statistics              â”‚
â”‚    âœ… Deployed to production (December 26, 2025)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5b. TRAINING FILES MIGRATION (Section E03b)                 â”‚
â”‚    â†’ POST /api/datasets/migrate (import training_files)     â”‚
â”‚    â†’ Maps training-files bucket to datasets table           â”‚
â”‚    â†’ Sets status='ready', training_ready=true               â”‚
â”‚    âœ… Deployed to production (December 27, 2025)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. TRAINING JOB CONFIGURATION (Section E03)                 â”‚
â”‚    â†’ POST /api/jobs/estimate (cost calculation)             â”‚
â”‚    â†’ POST /api/jobs (create job with status='queued')       â”‚
â”‚    â†’ GET /api/jobs (list jobs with pagination)              â”‚
â”‚    â†’ /training/configure page (presets + real-time costs)   â”‚
â”‚    âœ… Deployed to production (December 27, 2025)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6.5 RUNPOD INFRASTRUCTURE SETUP (Section E04.5)             â”‚
â”‚    â†’ Network Volume: qwen-model-cache (240GB)               â”‚
â”‚    â†’ Model: Qwen3-Next-80B-A3B-Instruct (84GB cached)       â”‚
â”‚    â†’ Docker Worker: 5 files (handler, trainer, Dockerfile)  â”‚
â”‚    â†’ RunPod Template + Serverless Endpoint                  â”‚
â”‚    ðŸ”§ IN PROGRESS (December 28, 2025)                       â”‚
â”‚    âœ… Phase 1 complete: Volume + Model cached               â”‚
â”‚    â³ Phase 2 in progress: Docker worker code needed        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. TRAINING EXECUTION & MONITORING (Section E04)            â”‚
â”‚    â†’ Edge Function: process queued jobs                     â”‚
â”‚    â†’ RunPod API: Submit training jobs                       â”‚
â”‚    â†’ Real-time progress updates                             â”‚
â”‚    â†’ Job monitoring UI                                      â”‚
â”‚    â†’ Job cancellation                                       â”‚
â”‚    â³ To be implemented (AFTER E04.5 complete)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Database Schema Overview

**Core Tables** (Existing):
- `conversations` - Conversation metadata and status (has `id` PK and `conversation_id` business key)
- `training_files` - Aggregated training file metadata
- `training_file_conversations` - Junction table linking conversations to training files
- `personas` - Client personality profiles (3 active)
- `emotional_arcs` - Emotional progression patterns (10 total: 7 template, 3 edge_case)
- `training_topics` - Subject matter configuration (many active)
- `prompt_templates` - Generation templates (10 total: 7 template tier, 3 edge_case tier)
- `batch_jobs` - Batch generation job tracking
- `batch_items` - Individual items in batch jobs
- `failed_generations` - Failed generation error records

**LoRA Training Tables** (Section E01 - Deployed):
- `datasets` - Dataset metadata and validation results (23 columns, RLS enabled)
- `training_jobs` - Training job configuration and status tracking (Section E03 creates these)
- `metrics_points` - Training metrics time series (Section E04 will use this)
- `model_artifacts` - Trained model outputs and metadata (Section E04 will use this)
- `cost_records` - Training cost tracking (Section E04 will use this)
- `notifications` - User notifications (Section E03 creates these)

---

## ðŸš¨ Critical Bug Fixes Applied (December 27, 2025)

### Bug 1: Toast Import Error
**File**: `src/hooks/useTrainingConfig.ts`  
**Error**: `Module '"sonner"' has no exported member 'toast'`  
**Fix**: Corrected import syntax for sonner library  
**Status**: âœ… Fixed and deployed

### Bug 2: Missing Await
**File**: `src/app/api/jobs/estimate/route.ts`  
**Error**: `createServerSupabaseClient()` not awaited  
**Fix**: Added `await` keyword  
**Status**: âœ… Fixed and deployed

### Bug 3: React Query v5 API Change
**File**: `src/hooks/useTrainingConfig.ts` (useTrainingJob hook)  
**Error**: Using v4 API pattern in v5 environment  
**Old**: `refetchInterval: (data) => data && ...`  
**New**: `refetchInterval: (query) => query.state.data && ...`  
**Status**: âœ… Fixed and deployed

---

**Last Updated**: December 28, 2025  
**Session Focus**: Section E04.5 - RunPod Infrastructure Setup (Phase 1 complete, Phase 2 in progress)  
**Current State**: E01-E03b deployed to production, E04.5 network volume + model cached, Docker worker files created but empty  
**Document Version**: e04.5-runpod-setup (RunPod Infrastructure In Progress)  
**Next Phase**: Generate Docker worker code (5 files) â†’ Build/push Docker image â†’ Deploy RunPod endpoint â†’ Configure application  
**Implementation Location**: `C:\Users\james\Master\BrightHub\BRun\brightrun-trainer\` (separate from lora-pipeline repo)
